{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from random import shuffle\n",
    "import scipy\n",
    "import os\n",
    "import scipy.io.wavfile as wavfile\n",
    "import audioFeatureExtraction\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import fnmatch\n",
    "import sklearn.preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import (RandomForestClassifier, ExtraTreesClassifier,\n",
    "                              AdaBoostClassifier)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pprint\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding column for arousal and valence\n",
    "# 0 => low arousal, 2 => high arousal.\n",
    "# 0 => -ve valence, 2 => +ve valence\n",
    "     \n",
    "# ----------------------------------------------------------\n",
    "#              Label index         Arousal        Valence\n",
    "# 1. Anger          0 W               2              0\n",
    "# 2. Boredom        4 L               0              0\n",
    "# 3. Disguist       3 E               1              1\n",
    "# 4. Anxiety        2 A               1              0\n",
    "# 5. Happiness      1 F               2              2\n",
    "# 6. Sadness        6 T               1              0\n",
    "# 7. Neutral        5 N               1              1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictionModel_NN(x_train, x_validation, y_train, y_validation, hidden_layer, alpha, lr):\n",
    "\n",
    "     # label_encoder = LabelEncoder()\n",
    "     # y_validation = label_encoder.fit_transform(y_validation)\n",
    "\n",
    "     mlp = MLPClassifier(hidden_layer_sizes= (10,), max_iter=1000, alpha= alpha,\n",
    "                    solver='adam', tol=1e-4, random_state=1,\n",
    "                    learning_rate_init= lr)\n",
    "     mlp.fit(x_train, y_train)\n",
    "     predictions = mlp.predict_proba(x_validation).astype('float32')\n",
    "     pred_labels= mlp.predict(x_validation)\n",
    "     print accuracy_score(y_validation, pred_labels)\n",
    "     return predictions, pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictionModel_RF(x_train, x_validation, y_train, y_validation, hidden_layer, alpha, lr):\n",
    "\n",
    "     # label_encoder = LabelEncoder()\n",
    "     # y_validation = label_encoder.fit_transform(y_validation)\n",
    "\n",
    "     logistic = RandomForestClassifier(n_estimators=100)\n",
    "     logistic.fit(x_train, y_train)\n",
    "     predictions = logistic.predict_proba(x_validation)\n",
    "     pred_labels= logistic.predict(x_validation)\n",
    "     print accuracy_score(y_validation, pred_labels)\n",
    "     return predictions, pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictionModel_SVC(x_train, x_validation, y_train, y_validation, hidden_layer, alpha, lr):\n",
    "\n",
    "     # label_encoder = LabelEncoder()\n",
    "     # y_validation = label_encoder.fit_transform(y_validation)\n",
    "\n",
    "     svm = SVC()\n",
    "\n",
    "     svm.fit(x_train, y_train)\n",
    "     predictions = svm.predict_proba(x_validation)\n",
    "     pred_labels= svm.predict(x_validation) \n",
    "\n",
    "     print accuracy_score(y_validation, pred_labels)\n",
    "     return predictions, pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "arousal_dict={\n",
    "     0: ['L'],\n",
    "     1: ['A', 'E', 'N', 'T'],\n",
    "     2: ['F', 'W'] \n",
    "}\n",
    "\n",
    "valence_dict={\n",
    "     0: ['A', 'L', 'T', 'W'],\n",
    "     1: ['E', 'N'],\n",
    "     2: ['F'] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_predictionLabels_NN= {}\n",
    "index_predictionLabels_RF= {}\n",
    "index_predictionLabels_SVC= {}\n",
    "actual_predictionLables= {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arousal_NN(X_train, X_validation, ind_train, ind_validation, Y_trainA, Y_validationA):\n",
    "     \n",
    "     print '-----------------------------------------------------------------------------------'\n",
    "     print 'Calculating over Arousal...'\n",
    "\n",
    "     arousal_predictions_NN, pred_labelsA_NN = predictionModel_NN(X_train, X_validation, Y_trainA.ravel(), Y_validationA.ravel(), (250, 250), 1e-5, 0.001)\n",
    "\n",
    "     # now, get all indices from training data with individual arousals\n",
    "     for i in range (3): \n",
    "          validation_indices= ind_validation[ np.where(pred_labelsA_NN.astype(int) == i)[0] ]\n",
    "\n",
    "          x_arousali_train= X[ ind_train[ np.where(Y_trainA.astype(int) == i)[0] ] ].reshape(-1, X.shape[1])\n",
    "          x_arousali_validation= X[ validation_indices ].reshape(-1, X.shape[1])\n",
    "\n",
    "          y_arousali_train= Y[2][ ind_train[ np.where(Y_trainA.astype(int) == i)[0] ] ]\n",
    "          y_arousali_validation= Y[2][ validation_indices ]\n",
    "\n",
    "          if len (arousal_dict[i]) == 1:\n",
    "               for val in validation_indices:\n",
    "                    index_predictionLabels_NN[val[0]] = ( arousal_dict[i][0], 1 )\n",
    "          else:\n",
    "               pred, pred_label_values= predictionModel_NN (x_arousali_train, x_arousali_validation, y_arousali_train.ravel(), y_arousali_validation.ravel(), (250, 250), 1e-5, 0.001)\n",
    "               \n",
    "               for ind, val in enumerate(validation_indices):\n",
    "                    max_index= pred[ind].argmax(axis=0)\n",
    "\n",
    "                    if val[0] in index_predictionLabels_NN:\n",
    "                         if pred[ind][max_index] > index_predictionLabels_NN[val[0]][1]:\n",
    "                              index_predictionLabels_NN[ val[0] ]= ( arousal_dict[i][max_index], pred[ind][max_index] )\n",
    "                    else:\n",
    "                         index_predictionLabels_NN[ val[0] ]= ( arousal_dict[i][max_index], pred[ind][max_index] )     \n",
    "\n",
    "     print 'Prediction dictionary filled in for arousal predictions..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valence_NN(X_train, X_validation, ind_train, ind_validation, Y_trainV, Y_validationV):\n",
    "     print '-----------------------------------------------------------------------------------'\n",
    "     print 'Calculating over Valence...'\n",
    "\n",
    "     # over valence prediction\n",
    "     valence_predictions_NN, pred_labelsV_NN= predictionModel_NN(X_train, X_validation, Y_trainV.ravel(), Y_validationV.ravel(), (500, 50), 1e-5, 0.0001)\n",
    "\n",
    "     # now, get all indices from training data with individual valence\n",
    "     for i in range (3): \n",
    "\n",
    "          validation_indices= ind_validation[ np.where(pred_labelsV_NN.astype(int) == i)[0] ]\n",
    "\n",
    "          x_valencei_train= X[ ind_train[ np.where(Y_trainV.astype(int) == i)[0] ] ].reshape(-1, X.shape[1])\n",
    "          x_valencei_validation= X[ validation_indices ].reshape(-1, X.shape[1])\n",
    "\n",
    "          y_valencei_train= Y[2][ ind_train[ np.where(Y_trainV.astype(int) == i)[0] ] ]\n",
    "          y_valencei_validation= Y[2][ validation_indices ]\n",
    "\n",
    "          if len (valence_dict[i]) == 1:\n",
    "               for val in validation_indices:\n",
    "                    index_predictionLabels_NN[val[0]] = ( valence_dict[i][0], 1 )\n",
    "          else:\n",
    "               pred, pred_label_values= predictionModel_NN (x_valencei_train, x_valencei_validation, y_valencei_train.ravel(), y_valencei_validation.ravel(), (500, 50), 1e-5, 0.0001)\n",
    "\n",
    "               for ind, val in enumerate(validation_indices):\n",
    "                    max_index= pred[ind].argmax(axis=0)\n",
    "\n",
    "                    if val[0] in index_predictionLabels_NN:\n",
    "                         if pred[ind][max_index] > index_predictionLabels_NN[val[0]][1]:\n",
    "                              index_predictionLabels_NN[ val[0] ]= ( valence_dict[i][max_index], pred[ind][max_index] )\n",
    "                    else:\n",
    "                         index_predictionLabels_NN[ val[0] ]= ( valence_dict[i][max_index], pred[ind][max_index] )     \n",
    "\n",
    "     print 'Prediction dictionary filled in for valence predictions..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arousal_RF(X_train, X_validation, ind_train, ind_validation, Y_trainA, Y_validationA):\n",
    "     arousal_predictions_RF, pred_labelsA_RF = predictionModel_RF(X_train, X_validation, Y_trainA.ravel(), Y_validationA.ravel(), (250, 250), 1e-5, 0.001)\n",
    "     for i in range (3): \n",
    "          validation_indices= ind_validation[ np.where(pred_labelsA_RF.astype(int) == i)[0] ]\n",
    "\n",
    "          x_arousali_train= X[ ind_train[ np.where(Y_trainA.astype(int) == i)[0] ] ].reshape(-1, X.shape[1])\n",
    "          x_arousali_validation= X[ validation_indices ].reshape(-1, X.shape[1])\n",
    "\n",
    "          y_arousali_train= Y[2][ ind_train[ np.where(Y_trainA.astype(int) == i)[0] ] ]\n",
    "          y_arousali_validation= Y[2][ validation_indices ]\n",
    "\n",
    "          if len (arousal_dict[i]) == 1:\n",
    "               for val in validation_indices:\n",
    "                    index_predictionLabels_RF[val[0]] = ( arousal_dict[i][0], 1 )\n",
    "          else:\n",
    "               pred, pred_label_values= predictionModel_RF (x_arousali_train, x_arousali_validation, y_arousali_train.ravel(), y_arousali_validation.ravel(), (250, 250), 1e-5, 0.001)\n",
    "               \n",
    "               for ind, val in enumerate(validation_indices):\n",
    "                    max_index= pred[ind].argmax(axis=0)\n",
    "                    if val[0] in index_predictionLabels_RF:\n",
    "                         if pred[ind][max_index] > index_predictionLabels_RF[val[0]][1]:\n",
    "                              index_predictionLabels_RF[ val[0] ]= ( arousal_dict[i][max_index], pred[ind][max_index] )\n",
    "                    else:\n",
    "                         index_predictionLabels_RF[ val[0] ]= ( arousal_dict[i][max_index], pred[ind][max_index] )     \n",
    "\n",
    "     print 'Prediction dictionary filled in for arousal predictions..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valence_RF(X_train, X_validation, ind_train, ind_validation, Y_trainV, Y_validationV):\n",
    "     print '-----------------------------------------------------------------------------------'\n",
    "     print 'Calculating over Valence...'\n",
    "\n",
    "     valence_predictions_RF, pred_labelsV_RF= predictionModel_RF(X_train, X_validation, Y_trainV.ravel(), Y_validationV.ravel(), (500, 50), 1e-5, 0.0001)\n",
    "\n",
    "     # now, get all indices from training data with individual valence\n",
    "     for i in range (3): \n",
    "\n",
    "          validation_indices= ind_validation[ np.where(pred_labelsV_RF.astype(int) == i)[0] ]\n",
    "\n",
    "          x_valencei_train= X[ ind_train[ np.where(Y_trainV.astype(int) == i)[0] ] ].reshape(-1, X.shape[1])\n",
    "          x_valencei_validation= X[ validation_indices ].reshape(-1, X.shape[1])\n",
    "\n",
    "          y_valencei_train= Y[2][ ind_train[ np.where(Y_trainV.astype(int) == i)[0] ] ]\n",
    "          y_valencei_validation= Y[2][ validation_indices ]\n",
    "\n",
    "          if len (valence_dict[i]) == 1:\n",
    "               for val in validation_indices:\n",
    "                    index_predictionLabels_RF[val[0]] = ( valence_dict[i][0], 1 )\n",
    "          else:\n",
    "               pred, pred_label_values= predictionModel_RF (x_valencei_train, x_valencei_validation, y_valencei_train.ravel(), y_valencei_validation.ravel(), (500, 50), 1e-5, 0.0001)\n",
    "\n",
    "               for ind, val in enumerate(validation_indices):\n",
    "                    max_index= pred[ind].argmax(axis=0)\n",
    "\n",
    "                    if val[0] in index_predictionLabels_RF:\n",
    "                         if pred[ind][max_index] > index_predictionLabels_RF[val[0]][1]:\n",
    "                              index_predictionLabels_RF[ val[0] ]= ( valence_dict[i][max_index], pred[ind][max_index] )\n",
    "                    else:\n",
    "                         index_predictionLabels_RF[ val[0] ]= ( valence_dict[i][max_index], pred[ind][max_index] )     \n",
    "\n",
    "     print 'Prediction dictionary filled in for valence predictions..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(X_train, X_validation, ind_train, ind_validation, Y_trainA, Y_validationA, Y_trainV, Y_validationV):\n",
    "     arousal_NN(X_train, X_validation, ind_train, ind_validation, Y_trainA, Y_validationA)\n",
    "     valence_NN(X_train, X_validation, ind_train, ind_validation, Y_trainV, Y_validationV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF(X_train, X_validation, ind_train, ind_validation, Y_trainA, Y_validationA, Y_trainV, Y_validationV):\n",
    "     arousal_RF(X_train, X_validation, ind_train, ind_validation, Y_trainA, Y_validationA)\n",
    "     valence_RF(X_train, X_validation, ind_train, ind_validation, Y_trainV, Y_validationV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def SVC(X_train, X_validation, ind_train, ind_validation, Y_trainA, Y_validationA, Y_trainV, Y_validationV):\n",
    "#      arousal_SVC(X_train, X_validation, ind_train, ind_validation, Y_trainA, Y_validationA)\n",
    "#      valence_SVC(X_train, X_validation, ind_train, ind_validation, Y_trainV, Y_validationV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['F1_mean','F2_mean','F3_mean','F4_mean','F5_mean','F6_mean','F7_mean','F8_mean','F9_mean',\n",
    "                                        'F10_mean','F11_mean','F12_mean','F13_mean','F14_mean','F15_mean','F16_mean','F17_mean',\n",
    "                                        'F18_mean','F19_mean','F20_mean','F21_mean','F22_mean','F23_mean','F24_mean','F25_mean',\n",
    "                                        'F26_mean','F27_mean','F28_mean','F29_mean','F30_mean','F31_mean','F32_mean','F33_mean','F34_mean','F35_median',\n",
    "                                        'F36_median',\n",
    "                                        'F37_median','F38_median','F39_median','F40_median','F41_median','F42_median','F43_median','F44_median',\n",
    "                                        'F45_median','F46_median','F47_median',\n",
    "                                        'F48_median','F49_median','F50_median','F51_median','F52_median','F53_median','F54_median','F55_median',\n",
    "                                        'F56_median','F57_median','F58_median',\n",
    "                                        'F59_median','F60_median','F61_median','F62_median','F63_median','F64_median','F65_median','F66_median','F67_median','F68_median','F69_std','F70_std',\n",
    "                                        'F71_std','F72_std','F73_std','F74_std','F75_std','F76_std','F77_std','F78_std','F79_std',\n",
    "                                        'F80_std','F81_std','F82_std','F83_std','F84_std','F85_std','F86_std','F87_std','F88_std','F89_std',\n",
    "                                        'F90_std','F91_std','F92_std','F93_std','F94_std','F95_std','F96_std','F97_std','F98_std','F99_std',\n",
    "                                        'F100_std','F101_std','F102_std','F103_max','F104_max','F105_max','F106_max','F107_mmax','F108_max','F109_max',\n",
    "                                        'F110_max','F111_max','F112_max','F113_max','F114_max','F115_max','F116_max','F117_max','F118_max','F119_max',\n",
    "                                        'F120_max','F121_max','F122_max','F123_max','F124_max','F125_max','F126_max','F127_max','F128_max','F129_max',\n",
    "                                        'F130_max','F131_max','F132_max','F133_max','F134_max','F135_max','F136_max','F137_min','F138_min','F139_min',\n",
    "                                        'F140_min','F141_min','F142_min','F143_min','F144_min','F145_min','F146_min','F147_min','F148_min','F149_min',\n",
    "                                        'F150_min','F151_min','F152_min','F153_min','F154_min','F155_min','F156_min','F157_min','F158_min','F159_min',\n",
    "                                        'F160_min','F161_min','F162_min','F163_min','F164_min','F165_min','F166_min','F167_min','F168_min','F169_min',\n",
    "                                        'F170_min','Arousal', 'Valence', 'Labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = ['F1_mean','F2_mean','F3_mean','F4_mean','F5_mean','F6_mean','F7_mean','F8_mean','F9_mean',\n",
    "#                                         'F10_mean','F11_mean','F12_mean','F13_mean','F14_mean','F15_mean','F16_mean','F17_mean',\n",
    "#                                         'F18_mean','F19_mean','F20_mean','F21_mean','F22_mean','F23_mean','F24_mean','F25_mean',\n",
    "#                                         'F26_mean','F27_mean','F28_mean','F29_mean','F30_mean','F31_mean','F32_mean','F33_mean','F34_mean','F35_median',\n",
    "#                                         'F36_median',\n",
    "#                                         'F37_median','F38_median','F39_median','F40_median','F41_median','F42_median','F43_median','F44_median',\n",
    "#                                         'F45_median','F46_median','F47_median',\n",
    "#                                         'F48_median','F49_median','F50_median','F51_median','F52_median','F53_median','F54_median','F55_median',\n",
    "#                                         'F56_median','F57_median','F58_median',\n",
    "#                                         'F59_median','F60_median','F61_median','F62_median','F63_median','F64_median','F65_median','F66_median','F67_median','F68_median','F69_std','F70_std',\n",
    "#                                         'F71_std','F72_std','F73_std','F74_std','F75_std','F76_std','F77_std','F78_std','F79_std',\n",
    "#                                         'F80_std','F81_std','F82_std','F83_std','F84_std','F85_std','F86_std','F87_std','F88_std','F89_std',\n",
    "#                                         'F90_std','F91_std','F92_std','F93_std','F94_std','F95_std','F96_std','F97_std','F98_std','F99_std',\n",
    "#                                         'F100_std','F101_std','F102_std','F103_max','F104_max','F105_max', 'Arousal', 'Valence', 'Labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('speech_dataset.shape', (536, 173))\n"
     ]
    }
   ],
   "source": [
    "speech_dataset= pd.read_csv('central_features.csv',names=names)\n",
    "print('speech_dataset.shape', speech_dataset.shape)\n",
    "\n",
    "array = speech_dataset.values[1:,]\n",
    "X = array[:, :170]\n",
    "Y = [array[:, 170], array[:, 171], array[:, 172]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array = speech_dataset.values[1:,]\n",
    "# X = array[:, :105]\n",
    "# Y = [array[:, 105], array[:, 106], array[:, 107]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = 0.1\n",
    "seed = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('array size', (535, 173))\n",
      "('X', (535, 170))\n",
      "('Y joint', 3)\n"
     ]
    }
   ],
   "source": [
    "print ('array size', array.shape)\n",
    "print ('X', X.shape)\n",
    "print ('Y joint', len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('new X', (535, 70))\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=70, copy=False)\n",
    "X=pca.fit_transform(X)\n",
    "# print('selected', pca.singular_values_ )  \n",
    "\n",
    "print ('new X', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape (481, 1)\n",
      "testing data shape (54, 1)\n"
     ]
    }
   ],
   "source": [
    "index_arr= np.arange(array.shape[0]).reshape(-1, 1)\n",
    "X_train, X_validation, ind_train, ind_validation= model_selection.train_test_split(X, index_arr, test_size=validation_size, random_state=seed)\n",
    "\n",
    "print 'training data shape', ind_train.shape\n",
    "print 'testing data shape', ind_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forming train and validation labels for arousal and valence resp\n",
    "Y_trainA, Y_validationA= Y[0][ind_train], Y[0][ind_validation]\n",
    "Y_trainV, Y_validationV= Y[1][ind_train], Y[1][ind_validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing with actual validation labels...\n"
     ]
    }
   ],
   "source": [
    "for i in ind_validation:\n",
    "     i= i[0]\n",
    "     actual_predictionLables[i] = Y[2][i]\n",
    "    \n",
    "print 'Comparing with actual validation labels...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printAccuracy(final_predictions):\n",
    "\n",
    "     # print 'final_predictions', final_predictions\n",
    "     # print 'actual_predictionLables', actual_predictionLables\n",
    "\n",
    "     num_correctPredicted, num_wrongPredicted= 0, 0\n",
    "     for i in ind_validation:\n",
    "          i= i[0]\n",
    "          if final_predictions[i][0] == actual_predictionLables[i]:\n",
    "               num_correctPredicted+=1\n",
    "          else:\n",
    "               num_wrongPredicted+=1\n",
    "\n",
    "     print 'num_correctPredicted', num_correctPredicted\n",
    "     print 'num_wrongPredicted', num_wrongPredicted\n",
    "     print 'accuracy', float(num_correctPredicted) / (num_correctPredicted + num_wrongPredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(actual_dict, predicted_dict):\n",
    "     actual= []\n",
    "     predicted= []\n",
    "     labels= ['A', 'E', 'F', 'L', 'N', 'T', 'W']\n",
    "     for i, val in enumerate(ind_validation):\n",
    "          actual.append( actual_dict[ val[0] ] )\n",
    "          predicted.append( predicted_dict[ val[0] ][0] )\n",
    "\n",
    "     print confusion_matrix(actual, predicted, labels= labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************************************\n",
      "NN\n",
      "*********************************************************************************\n",
      "-----------------------------------------------------------------------------------\n",
      "Calculating over Arousal...\n",
      "0.740740740741\n",
      "0.689655172414\n",
      "0.714285714286\n",
      "Prediction dictionary filled in for arousal predictions..\n",
      "-----------------------------------------------------------------------------------\n",
      "Calculating over Valence...\n",
      "0.703703703704\n",
      "0.487804878049\n",
      "0.666666666667\n",
      "Prediction dictionary filled in for valence predictions..\n"
     ]
    }
   ],
   "source": [
    "print '*********************************************************************************'\n",
    "print 'NN'\n",
    "print '*********************************************************************************'\n",
    "NN(X_train, X_validation, ind_train, ind_validation, Y_trainA, Y_validationA, Y_trainV, Y_validationV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN\n",
      "num_correctPredicted 39\n",
      "num_wrongPredicted 15\n",
      "accuracy 0.722222222222\n",
      "NN confusion matrix\n",
      "[[6 0 0 0 0 0 0]\n",
      " [0 5 0 0 0 0 3]\n",
      " [1 0 3 0 0 0 1]\n",
      " [0 0 0 5 0 0 0]\n",
      " [0 0 0 5 5 0 0]\n",
      " [0 0 0 1 2 6 0]\n",
      " [1 0 0 0 1 0 9]]\n"
     ]
    }
   ],
   "source": [
    "print 'NN'\n",
    "printAccuracy(index_predictionLabels_NN)\n",
    "\n",
    "print 'NN confusion matrix'\n",
    "print_confusion_matrix(actual_predictionLables, index_predictionLabels_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************************************\n",
      "RF\n",
      "*********************************************************************************\n",
      "0.796296296296\n",
      "0.666666666667\n",
      "0.722222222222\n",
      "Prediction dictionary filled in for arousal predictions..\n",
      "-----------------------------------------------------------------------------------\n",
      "Calculating over Valence...\n",
      "0.611111111111\n",
      "0.519230769231\n",
      "1.0\n",
      "Prediction dictionary filled in for valence predictions..\n"
     ]
    }
   ],
   "source": [
    "print '*********************************************************************************'\n",
    "print 'RF'\n",
    "print '*********************************************************************************'\n",
    "RF(X_train, X_validation, ind_train, ind_validation, Y_trainA, Y_validationA, Y_trainV, Y_validationV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF\n",
      "num_correctPredicted 38\n",
      "num_wrongPredicted 16\n",
      "accuracy 0.703703703704\n",
      "RF confusion matrix\n",
      "[[ 6  0  0  0  0  0  0]\n",
      " [ 0  4  0  0  0  0  4]\n",
      " [ 0  1  2  0  1  0  1]\n",
      " [ 0  0  0  4  1  0  0]\n",
      " [ 1  0  0  4  5  0  0]\n",
      " [ 0  0  0  1  2  6  0]\n",
      " [ 0  0  0  0  0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "print 'RF'\n",
    "printAccuracy(index_predictionLabels_RF)\n",
    "\n",
    "print 'RF confusion matrix'\n",
    "print_confusion_matrix(actual_predictionLables, index_predictionLabels_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
